{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN1D+zZhcokDqlfYZS6LBbz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vedalaxman/Audio_to_Text/blob/main/Wishper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "95xfJwnXn2SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "id": "s-U3a5OfxGRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "8tuzKLvb12yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq, BitsAndBytesConfig\n",
        "model_id = \"Na0s/Medical-Whisper-Large-v3\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"Loading model on device: {device}\")\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "print(\"Processor Loaded\")\n",
        "if device == \"cuda\":\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_8bit=True,\n",
        "        bnb_8bit_compute_dtype=torch.float16\n",
        "    )\n",
        "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "        model_id,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "        use_safetensors=True\n",
        "    )\n",
        "    print(\"Model Loaded in 8-bit precision with float16 compute dtype.\")\n",
        "else:\n",
        "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float32,\n",
        "        low_cpu_mem_usage=True,\n",
        "        use_safetensors=True\n",
        "    ).to(device)\n",
        "    print(\"Model Loaded on CPU in float32 precision.\")\n",
        "\n",
        "print(\"Model Loaded\")"
      ],
      "metadata": {
        "id": "tCSDkPqEn1L0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/eval-00000-of-00001.parquet'\n",
        "\n",
        "try:\n",
        "    df = pd.read_parquet(file_path)\n",
        "    print('Done')\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found: {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error reading Parquet: {e}\")"
      ],
      "metadata": {
        "id": "yk9Cdsdun1Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "yUSz5ONmM2rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, Audio\n",
        "import librosa"
      ],
      "metadata": {
        "id": "2Yqlm8Oon1Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/*dataset = Dataset.from_pandas(df)\n",
        "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "\n",
        "columns_to_remove = []\n",
        "if 'audio_id' in dataset.features:\n",
        "    columns_to_remove.append('audio_id')\n",
        "if 'duration' in dataset.features:\n",
        "    columns_to_remove.append('duration')\n",
        "\n",
        "if columns_to_remove:\n",
        "    dataset = dataset.remove_columns(columns_to_remove)"
      ],
      "metadata": {
        "id": "OiaTmk7DNStG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "08YHbb8PNSwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = dataset.select(range(5))"
      ],
      "metadata": {
        "id": "g3zrdIDZNS4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "id": "uQp235nWSysk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio_batch(batch):\n",
        "    audio_inputs = [item[\"array\"] for item in batch[\"audio\"]]\n",
        "    input_features = processor.feature_extractor(\n",
        "        audio_inputs,\n",
        "        sampling_rate=16000,\n",
        "        return_tensors=\"pt\"\n",
        "    ).input_features.to(device)\n",
        "    if device == \"cuda\":\n",
        "        input_features = input_features.to(torch.float16)\n",
        "    predicted_ids = model.generate(input_features, language=\"en\", task=\"transcribe\")\n",
        "    transcriptions = processor.tokenizer.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "    return {\"transcribed_text\": transcriptions}"
      ],
      "metadata": {
        "id": "WKYMoXQMSyva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcription_results_dataset = test_df.map(\n",
        "    transcribe_audio_batch,\n",
        "    batched=True,\n",
        "    batch_size=1,\n",
        "    remove_columns=[\"audio\"]\n",
        ")\n",
        "\n",
        "df_final = transcription_results_dataset.to_pandas"
      ],
      "metadata": {
        "id": "R1LsyT_tSyye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final"
      ],
      "metadata": {
        "id": "LQdm94gF38F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "import librosa"
      ],
      "metadata": {
        "id": "uAhyc5Mu4Ua5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_single_audio(audio_path):\n",
        "    speech_array, sr = librosa.load(audio_path, sr=16000)\n",
        "    input_features = processor.feature_extractor(\n",
        "        speech_array,\n",
        "        sampling_rate=sr,\n",
        "        return_tensors=\"pt\"\n",
        "    ).input_features.to(device)\n",
        "    if device == \"cuda\":\n",
        "        input_features = input_features.to(torch.float16)\n",
        "    predicted_ids = model.generate(input_features, language=\"en\", task=\"transcribe\")\n",
        "    transcription = processor.tokenizer.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "    return transcription"
      ],
      "metadata": {
        "id": "JyhDebZ74Udw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_path = '/content/OSR_us_000_0011_8k.wav'"
      ],
      "metadata": {
        "id": "NW2cT8cq4Ugf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = transcribe_single_audio(audio_path)"
      ],
      "metadata": {
        "id": "0BffCOUQ4Ujl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "id": "wvLELBh-5g6Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}